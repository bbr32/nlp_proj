{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_proj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbr32/nlp_proj/blob/master/NLP_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7-yq3ojromU",
        "colab_type": "code",
        "outputId": "e10e973f-ab62-4808-dce0-b4e195b71897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from keras.callbacks import Callback\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import re\n",
        "\n",
        "from keras import backend as K\n",
        "import keras.layers as layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Input, Dropout, Dense, concatenate, Embedding, Flatten, Activation, SpatialDropout1D\n",
        "from keras.layers import Bidirectional, GRU, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.utils import np_utils\n",
        "from keras.engine import Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "from keras.layers import *\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import LSTM, CuDNNGRU, CuDNNLSTM, Add, Reshape\n",
        "from keras.layers import MaxPooling1D, Conv1D, MaxPooling1D, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "os.environ['OMP_NUM_THREADS'] = '4'\n",
        "\n",
        "\n",
        "import re\n",
        "import math\n",
        "# set seed\n",
        "np.random.seed(123)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckb4R-zs__az",
        "colab_type": "code",
        "outputId": "61b13d15-2805-494b-a3ab-abea57b629b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/bbr32/nlp_proj/master/dataset_test_no_labels.csv\n",
        "!wget https://raw.githubusercontent.com/bbr32/nlp_proj/master/dataset_train.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-21 11:36:10--  https://raw.githubusercontent.com/bbr32/nlp_proj/master/dataset_test_no_labels.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3537628 (3.4M) [text/plain]\n",
            "Saving to: ‘dataset_test_no_labels.csv’\n",
            "\n",
            "\r          dataset_t   0%[                    ]       0  --.-KB/s               \rdataset_test_no_lab 100%[===================>]   3.37M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2019-12-21 11:36:11 (55.8 MB/s) - ‘dataset_test_no_labels.csv’ saved [3537628/3537628]\n",
            "\n",
            "--2019-12-21 11:36:11--  https://raw.githubusercontent.com/bbr32/nlp_proj/master/dataset_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 74546358 (71M) [text/plain]\n",
            "Saving to: ‘dataset_train.csv’\n",
            "\n",
            "dataset_train.csv   100%[===================>]  71.09M   293MB/s    in 0.2s    \n",
            "\n",
            "2019-12-21 11:36:12 (293 MB/s) - ‘dataset_train.csv’ saved [74546358/74546358]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXBR_DIP_5hv",
        "colab_type": "code",
        "outputId": "e8b024e3-df61-4bde-ba37-9de147e6338f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df = pd.read_csv('dataset_train.csv', sep='\\t')\n",
        "df = df.drop(columns=\"index\")\n",
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_1</th>\n",
              "      <th>sentence_2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Conceptually cream skimming has two basic dime...</td>\n",
              "      <td>Product and geography are what make cream skim...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>you know during the season and i guess at at y...</td>\n",
              "      <td>You lose the things to the following level if ...</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>One of our number will carry out your instruct...</td>\n",
              "      <td>A member of my team will execute your orders w...</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How do you know? All this is their information...</td>\n",
              "      <td>This information belongs to them.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yeah i tell you what though if you go price so...</td>\n",
              "      <td>The tennis shoes have a range of prices.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>my walkman broke so i'm upset now i just have ...</td>\n",
              "      <td>I'm upset that my walkman broke and now I have...</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>But a few Christian mosaics survive above the ...</td>\n",
              "      <td>Most of the Christian mosaics were destroyed b...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(Read  for Slate 's take on Jackson's findings.)</td>\n",
              "      <td>Slate had an opinion on Jackson's findings.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Gays and lesbians.</td>\n",
              "      <td>Heterosexuals.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>At the end of Rue des Francs-Bourgeois is what...</td>\n",
              "      <td>Place des Vosges is constructed entirely of gr...</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          sentence_1  ...          label\n",
              "0  Conceptually cream skimming has two basic dime...  ...        neutral\n",
              "1  you know during the season and i guess at at y...  ...     entailment\n",
              "2  One of our number will carry out your instruct...  ...     entailment\n",
              "3  How do you know? All this is their information...  ...     entailment\n",
              "4  yeah i tell you what though if you go price so...  ...        neutral\n",
              "5  my walkman broke so i'm upset now i just have ...  ...     entailment\n",
              "6  But a few Christian mosaics survive above the ...  ...        neutral\n",
              "7   (Read  for Slate 's take on Jackson's findings.)  ...     entailment\n",
              "8                                 Gays and lesbians.  ...  contradiction\n",
              "9  At the end of Rue des Francs-Bourgeois is what...  ...  contradiction\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKL-Xl7_AClU",
        "colab_type": "code",
        "outputId": "207a2aa0-8661-418f-9a39-1ca62e58c2eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_test = pd.read_csv('dataset_test_no_labels.csv', sep='\\t')\n",
        "test = df_test.drop(columns=\"index\")\n",
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_1</th>\n",
              "      <th>sentence_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One senior FAA air traffic control manager sai...</td>\n",
              "      <td>A senior FFA air traffic control manager said ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Once constructed, this persisting psychologica...</td>\n",
              "      <td>Once unique experiences become personally mean...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Help us continue to offer the finest professio...</td>\n",
              "      <td>Support us to keep offering the best professio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>At the end of the Wars of Spanish, Austrian, a...</td>\n",
              "      <td>Northern Italy was not easily given up to the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Update on the Democratic fund-raising scandal ...</td>\n",
              "      <td>Clinton said the agents had not told him anyth...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          sentence_1                                         sentence_2\n",
              "0  One senior FAA air traffic control manager sai...  A senior FFA air traffic control manager said ...\n",
              "1  Once constructed, this persisting psychologica...  Once unique experiences become personally mean...\n",
              "2  Help us continue to offer the finest professio...  Support us to keep offering the best professio...\n",
              "3  At the end of the Wars of Spanish, Austrian, a...  Northern Italy was not easily given up to the ...\n",
              "4  Update on the Democratic fund-raising scandal ...  Clinton said the agents had not told him anyth..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwoLOLzCAE7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val = train_test_split(df, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgCpq8oBAMel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rnn_data(df):\n",
        "    x = {\n",
        "        'sentence1': df[\"sentence_1\"],\n",
        "        #\n",
        "        'sentence2': df[\"sentence_2\"],\n",
        "        }\n",
        "    return x\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "X_train = get_rnn_data(train)\n",
        "Y_train = np_utils.to_categorical(le.fit_transform(train[\"label\"].values)).astype(\"int64\")\n",
        "\n",
        "X_val = get_rnn_data(val)\n",
        "Y_val = np_utils.to_categorical(le.fit_transform(val[\"label\"].values)).astype(\"int64\")\n",
        "\n",
        "X_test = get_rnn_data(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il_GXhsHhBXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8ec71d3b-d11e-4ed3-8a77-d570fecad07e"
      },
      "source": [
        "print(df.iloc[247326])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_1    The city's setting is picturesque Castilian ca...\n",
            "sentence_2              There are no farmhouses in the setting.\n",
            "label                                             contradiction\n",
            "Name: 247326, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo5DH3TWHzZf",
        "colab_type": "code",
        "outputId": "73fcf4f6-a8b3-42c0-9d16-9621711b42b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "print(X_train)\n",
        "print(Y_train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'sentence1': 247326    The city's setting is picturesque Castilian ca...\n",
            "338153    You saw maybe one hundred to one hundred and f...\n",
            "384955    but um all these places you know you can get l...\n",
            "348613    Finally, he managed something that was adequat...\n",
            "211463                        well lawyers help create that\n",
            "                                ...                        \n",
            "192476    Today, ruins of the Taira clan's dwellings are...\n",
            "17730                                        The Ascendancy\n",
            "28030     Then I remembered that enigmatical conversatio...\n",
            "277869                      address the core issues fairly?\n",
            "249342    definitely i can see why people wait until the...\n",
            "Name: sentence_1, Length: 353395, dtype: object, 'sentence2': 247326              There are no farmhouses in the setting.\n",
            "338153                         There were only two spotted.\n",
            "384955    You can get a nice meal at a lot of the places...\n",
            "348613      His attire was mismatched, but he did not care.\n",
            "211463           Lawyer's can create that complex contract.\n",
            "                                ...                        \n",
            "192476     There are still ruins of Taira clan's dwellings.\n",
            "17730                                        The dominance \n",
            "28030     Then I remember that Evelyn Howard hadn't spok...\n",
            "277869            Will the core issues be addressed fairly?\n",
            "249342                People can't wait to get another one.\n",
            "Name: sentence_2, Length: 353395, dtype: object}\n",
            "[[1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " ...\n",
            " [1 0 0]\n",
            " [0 1 0]\n",
            " [1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feOLSe37DrJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ElmoEmbeddingLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.dimensions = 1024\n",
        "        self.trainable=True\n",
        "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable,\n",
        "                               name=\"{}_module\".format(self.name))\n",
        "\n",
        "        self.trainable_weights += tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
        "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
        "                      as_dict=True,\n",
        "                      signature='default',\n",
        "                      )['default']\n",
        "        return result\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return K.not_equal(inputs, '--PAD--')\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.dimensions)\n",
        "    \n",
        "#     def get_config(self):\n",
        "#         config = {'output_dim': self.output_dim}\n",
        "    \n",
        "class NonMasking(Layer):   \n",
        "    def __init__(self, **kwargs):   \n",
        "        self.supports_masking = True  \n",
        "        super(NonMasking, self).__init__(**kwargs)   \n",
        "  \n",
        "    def build(self, input_shape):   \n",
        "        input_shape = input_shape   \n",
        "  \n",
        "    def compute_mask(self, input, input_mask=None):   \n",
        "        # do not pass the mask to the next layers   \n",
        "        return None   \n",
        "  \n",
        "    def call(self, x, mask=None):   \n",
        "        return x   \n",
        "  \n",
        "    def get_output_shape_for(self, input_shape):   \n",
        "        return input_shape\n",
        "    \n",
        "#     def get_config(self):\n",
        "#         config = {'output_dim': self.output_dim}\n",
        "        \n",
        "custom_ob={'ElmoEmbeddingLayer': ElmoEmbeddingLayer, 'NonMasking': NonMasking}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIUP0L2pCskb",
        "colab_type": "code",
        "outputId": "e5417582-0a7a-4689-aff9-2d69679b48d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def get_model():\n",
        "    model = Sequential()\n",
        "    inp1 = Input(shape=(1,), dtype=\"string\", name=\"sentence1\")\n",
        "    inp2 = Input(shape=(1,), dtype=\"string\", name=\"sentence2\")\n",
        "    \n",
        "    def emb_layer(inp, col):\n",
        "        x = ElmoEmbeddingLayer()(inp)\n",
        "        return x\n",
        "\n",
        "    x = concatenate([\n",
        "                    emb_layer(inp1,\"sen_1\"),\n",
        "                    emb_layer(inp2,\"sen_2\"),\n",
        "                     ])\n",
        "    \n",
        "    x = NonMasking()(x)\n",
        "    x = Reshape((1, 1024*2), input_shape=(1024*2,))(x)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True,recurrent_dropout=0.2))(x)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True,recurrent_dropout=0.2))(x)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True,recurrent_dropout=0.2))(x)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True,recurrent_dropout=0.2))(x)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True,recurrent_dropout=0.2))(x)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True,recurrent_dropout=0.2))(x)\n",
        "\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    x = concatenate([avg_pool, max_pool])\n",
        "\n",
        "    outp = Dense(3, activation=\"softmax\", name=\"final_output\")(x)\n",
        "    \n",
        "    model = Model(inputs=[inp1,inp2], outputs=outp)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=Adam(lr=0.001),\n",
        "                  metrics=['accuracy'],\n",
        "                 )\n",
        "\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "sentence1 (InputLayer)          (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sentence2 (InputLayer)          (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "elmo_embedding_layer_1 (ElmoEmb (None, 1024)         4           sentence1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "elmo_embedding_layer_2 (ElmoEmb (None, 1024)         4           sentence2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 2048)         0           elmo_embedding_layer_1[0][0]     \n",
            "                                                                 elmo_embedding_layer_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "non_masking_1 (NonMasking)      (None, 2048)         0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 2048)      0           non_masking_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 1, 256)       2229248     reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 1, 256)       394240      bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 1, 256)       394240      bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 1, 256)       394240      bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 1, 256)       394240      bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) (None, 1, 256)       394240      bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_1 (Glo (None, 256)          0           bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 256)          0           bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 512)          0           global_average_pooling1d_1[0][0] \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "final_output (Dense)            (None, 3)            1539        concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 4,201,995\n",
            "Trainable params: 4,201,995\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCKqNMKnT6yY",
        "colab_type": "code",
        "outputId": "044b236f-9ed9-49aa-d5ed-9630d9067e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbZiqcMlA9BP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=1, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5,\n",
        "                                            min_lr=0.00001)\n",
        "file_path='checkpoint_SNLI_weights.hdf5'\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=1)\n",
        "\n",
        "model_callbacks = [checkpoint, early, learning_rate_reduction]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI-ew5wjBkOo",
        "colab_type": "code",
        "outputId": "4193cfe8-6729-404c-dc07-105a9eb8a018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=32,\n",
        "          epochs=5,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val, Y_val),\n",
        "          callbacks = model_callbacks\n",
        "         )\n",
        "\n",
        "model.save_weights(\"/content/drive/My Drive/Colab Notebooks/NLP Projet/SNLI_weights.hdf5\")\n",
        "model.save(\"/content/drive/My Drive/Colab Notebooks/NLP Projet/SNLI_model.h5\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 353395 samples, validate on 39267 samples\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:200: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:200: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "353395/353395 [==============================] - 3859s 11ms/step - loss: 0.9416 - acc: 0.5303 - val_loss: 0.8700 - val_acc: 0.5953\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.59531, saving model to checkpoint_SNLI_weights.hdf5\n",
            "Epoch 2/5\n",
            "353395/353395 [==============================] - 3827s 11ms/step - loss: 0.8333 - acc: 0.6211 - val_loss: 0.8273 - val_acc: 0.6219\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.59531 to 0.62192, saving model to checkpoint_SNLI_weights.hdf5\n",
            "Epoch 3/5\n",
            "353395/353395 [==============================] - 3828s 11ms/step - loss: 0.7863 - acc: 0.6516 - val_loss: 0.8121 - val_acc: 0.6336\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.62192 to 0.63359, saving model to checkpoint_SNLI_weights.hdf5\n",
            "Epoch 4/5\n",
            "353395/353395 [==============================] - 3755s 11ms/step - loss: 0.7493 - acc: 0.6716 - val_loss: 0.8053 - val_acc: 0.6417\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.63359 to 0.64166, saving model to checkpoint_SNLI_weights.hdf5\n",
            "Epoch 5/5\n",
            "353395/353395 [==============================] - 3718s 11ms/step - loss: 0.7150 - acc: 0.6899 - val_loss: 0.8100 - val_acc: 0.6409\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.64166\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_RwjjDBcpvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"/content/drive/My Drive/Colab Notebooks/NLP Projet/SNLI_weights_final.hdf5\")\n",
        "model.save(\"/content/drive/My Drive/Colab Notebooks/NLP Projet/SNLI_model_final.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYf4q34gEsft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_acc = (np.argmax(test_pred, axis=1) == np.argmax(Y_test, axis=1)).sum()/Y_test.shape[0] * 100\n",
        "\n",
        "print(\"Accuracy on test set is: %\"+str(test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7-pS97JDAIl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0e249c16-42be-458f-dbb8-08171af0e2c1"
      },
      "source": [
        "%%time\n",
        "Y_test = model.predict(X_test, batch_size=32, verbose=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19647/19647 [==============================] - 164s 8ms/step\n",
            "CPU times: user 3min 35s, sys: 19.2 s, total: 3min 54s\n",
            "Wall time: 2min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGdWysXde5ZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "76954650-4353-4c25-e482-1e49fd47d2a5"
      },
      "source": [
        "print(Y_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.20362063 0.6551076  0.14127173]\n",
            " [0.0371866  0.67752326 0.28529015]\n",
            " [0.09883515 0.28891495 0.6122499 ]\n",
            " ...\n",
            " [0.40951046 0.04684327 0.5436462 ]\n",
            " [0.29094517 0.28632495 0.42272988]\n",
            " [0.04219276 0.1458739  0.81193334]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34p6EC9GRM66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_final = pd.DataFrame({\"label\": [Y_test]})\n",
        "data_final.to_csv(\"/content/drive/My Drive/Colab Notebooks/NLP Projet/predictions.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q-E5FL_gkG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_csv(predicted, label_map, verbosity=False):\n",
        "    \"\"\"\n",
        "        Generate CSV with predicted results and\n",
        "        required form from the return of predict function and \n",
        "        the maping dictionnary {int: 'value'} \n",
        "    \"\"\"\n",
        "    import csv\n",
        "    from google.colab import files\n",
        "    predicted_results = np.argmax(predicted, axis=1)\n",
        "    if verbosity: print(label_map)\n",
        "    dict_data=[]\n",
        "    for i, v in enumerate(predicted_results): \n",
        "      d={'index':i, 'label':label_map[v]}\n",
        "      dict_data.append(d)\n",
        "    if verbosity: print(dict_data)\n",
        "    csv_file='results.csv'\n",
        "    try:\n",
        "        with open(csv_file, 'w') as csvfile:\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=['index', 'label'])\n",
        "            writer.writeheader()\n",
        "            for data in dict_data:\n",
        "                writer.writerow(data)\n",
        "    except IOError:\n",
        "        print(\"I/O error\")\n",
        "    files.download('results.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6hKWo_Wc4g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = {'neutral':2, 'entailment':1, 'contradiction':0}\n",
        "classes = {v: k for k, v in classes.items()}\n",
        "gen_csv(Y_test, classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnDaW5WngJsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}